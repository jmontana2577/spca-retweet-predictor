{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2 - Combine Data and Add Columns\n",
    "The purpose of this notebook is threefold:  \n",
    "1. Convert pandas timestamp to a datetime aware object adjusted for time zone.\n",
    "1. Add some features to the data - country and individual date components: year, month, hour (organization's local time) and day of week (where 0 = Monday, 1 = Tuesday, etc.). \n",
    "1. Join all the dataframes into one.\n",
    "1. Convert the hashtags and mentions columns to prep them for count vectorization in a later notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write code to adjust dates and times according to DST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# function that replaces pandas timestamp with timezone adjusted datetime aware object\n",
    "def convert_to_datetime_aware(date, tz=None):\n",
    "    '''\n",
    "    Parameters: \n",
    "        date - pandas UTC timestamp , \n",
    "        tz - a pytz time zone to convert to (default is None)\n",
    "    \n",
    "    Returns:\n",
    "        datetime aware object in specified time zone (UTC if None)\n",
    "    \n",
    "    '''\n",
    "    utc_zone = pytz.timezone('UTC')\n",
    "    date = date.to_pydatetime().replace(tzinfo=utc_zone)\n",
    "    \n",
    "    if tz:\n",
    "        return date.astimezone(tz)\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that adds separate date attribute columns\n",
    "def add_date_features(df):\n",
    "    df['year'] = df.date.apply(lambda x: x.year)\n",
    "    df['month'] = df.date.apply(lambda x: x.month)\n",
    "    df['weekday'] = df.date.apply(lambda x: x.weekday())\n",
    "    df['hour'] = df.date.apply(lambda x: x.hour)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the time zones\n",
    "et_zone = pytz.timezone('US/Eastern')\n",
    "ct_zone = pytz.timezone('US/Central')\n",
    "mt_zone = pytz.timezone('US/Mountain')\n",
    "pt_zone = pytz.timezone('US/Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import individual organization's tweets from the pickle files\n",
    "df_sfspca = pd.read_pickle('../data/1-sfspca_tweets.p')\n",
    "df_pspca = pd.read_pickle('../data/1-pspca_tweets.p')\n",
    "df_houston = pd.read_pickle('../data/1-houston_tweets.p')\n",
    "df_texas = pd.read_pickle('../data/1-texas_tweets.p')\n",
    "df_tulsa = pd.read_pickle('../data/1-tulsa_tweets.p')\n",
    "df_richmond = pd.read_pickle('../data/1-richmond_tweets.p')\n",
    "df_ontario = pd.read_pickle('../data/1-ontario_tweets.p')\n",
    "df_alberta = pd.read_pickle('../data/1-alberta_tweets.p')\n",
    "df_bc = pd.read_pickle('../data/1-bc_tweets.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date column of each dataframe to local time zone datetime aware object\n",
    "df_sfspca['date'] = df_sfspca.date.apply(convert_to_datetime_aware, args=(pt_zone,))\n",
    "df_pspca['date'] = df_pspca.date.apply(convert_to_datetime_aware, args=(et_zone,))\n",
    "df_houston['date'] = df_houston.date.apply(convert_to_datetime_aware, args=(ct_zone,))\n",
    "df_texas['date'] = df_texas.date.apply(convert_to_datetime_aware, args=(ct_zone,))\n",
    "df_tulsa['date'] = df_tulsa.date.apply(convert_to_datetime_aware, args=(ct_zone,))\n",
    "df_richmond['date'] = df_richmond.date.apply(convert_to_datetime_aware, args=(et_zone,))\n",
    "df_ontario['date'] = df_ontario.date.apply(convert_to_datetime_aware, args=(et_zone,))\n",
    "df_alberta['date'] = df_alberta.date.apply(convert_to_datetime_aware, args=(mt_zone,))\n",
    "df_bc['date'] = df_bc.date.apply(convert_to_datetime_aware, args=(pt_zone,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join dataframes based on country to add the country column\n",
    "df_usa = pd.concat([df_sfspca, df_pspca, df_houston, df_texas, df_tulsa, df_richmond], ignore_index=True)\n",
    "df_canada = pd.concat([df_ontario, df_alberta, df_bc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22471, 12), (70300, 12))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add country to each dataframe\n",
    "df_usa['country'] = 'usa'\n",
    "df_canada['country'] = 'canada'\n",
    "df_usa.shape, df_canada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92771, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine into one dataframe\n",
    "df = pd.concat([df_usa, df_canada], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92771, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add columns for year, month, weekday, and hour\n",
    "df = add_date_features(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change name of date column to local_datetime\n",
    "df.rename(columns={'date':'local_datetime'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92771, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hashtags are clean so only need to make them lowercase\n",
    "df['hashtags'] = df.hashtags.apply(lambda x: x.lower())\n",
    "df['mentions'] = df.mentions.apply(lambda x: x.lower())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../data/2-all_tweets.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
