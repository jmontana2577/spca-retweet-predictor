{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 1 - Get Tweets using GetOldTweets\n",
    "The purpose of this notebook is to gather the tweets. Scott Tarlow, a contact shared with me by my advisor Joshua Cook, directed me to this GetOldTweets-python repo (https://github.com/Jefferson-Henrique/GetOldTweets-python) to circumvent the limits of the Twitter API. Here are some of the tweeks I implemented in GetOldTweets to tailor it to my needs:  \n",
    "    \n",
    "**Problem:**  \n",
    "The functionality was written for Python2 and I'm using Python3.  \n",
    "\n",
    "**Fix:**  \n",
    "Replaced `urllib2` references with `urllib` in `getJsonReponse` function within `TweetManager.py`.   \n",
    "    \n",
    "**Problem:**  \n",
    "I also discovered that the more tweets I requested, the time to retrieve them grew exponentially. \n",
    "\n",
    "**Fix:**  \n",
    "Added functionality to pull tweets one month at a time and it does so at a rate of about 1500 tweets per minute (drastic improvement over the 100 minutes it took to pull 500 tweets previously).\n",
    "  \n",
    "**Problem:**  \n",
    "Tweets sent as replies to other tweets were being included. I only want original tweets.  \n",
    "  \n",
    "**Fix:**  \n",
    "I added a check in `getTweets` function within `TweetManager.py` and it skips replies.  \n",
    "  \n",
    "**Problem:**  \n",
    "The original code references a section of the Twitter API repsonse that no longer exists. It led to empty username and location data in the data frame.  \n",
    "  \n",
    "**Fix:**  \n",
    "I relocated where username is in the response, and updated the code. However, I could not find any location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /home/jovyan/capstone/GetOldTweets-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import got3 as got\n",
    "\n",
    "def get_tweets(username):\n",
    "    from collections import defaultdict\n",
    "    d = defaultdict(list)\n",
    "    \n",
    "    attributes = ['date', 'favorites', 'retweets', 'hashtags', 'id', 'mentions',\n",
    "                  'text', 'urls', 'username', 'permalink', 'author_id']\n",
    "\n",
    "    # created to efficiently pull tweets one month at a time\n",
    "    years = ['2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "    months = [('01', '31'), ('02', '28'), ('03', '31'), ('04', '30'), ('05', '31'), ('06', '30'),\n",
    "              ('07', '31'), ('08', '31'), ('09', '30'), ('10', '31'), ('11', '30'), ('12', '31')]\n",
    "    total = 0\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            # account for non-inclusive end of month by starting where previous month left off\n",
    "            if year == '2008' and month[0] == '01':\n",
    "                since = year + '-' + month[0] + '-01'\n",
    "            else:\n",
    "                since = until\n",
    "            until = year + '-' + month[0] + '-' + month[1]\n",
    "            tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since).setUntil(until)\n",
    "            tweet_list = got.manager.TweetManager.getTweets(tweetCriteria)                                                                                             \n",
    "            print('{} tweets from {} to {}.'.format(len(tweet_list), since, until))\n",
    "            total += len(tweet_list)\n",
    "            for tweet in tweet_list:\n",
    "                for att in attributes:\n",
    "                    d[att].append(eval(\"tweet.\" + att))\n",
    "    print('{} total tweets for {}.'.format(total, username))\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_and_export(filename, handle):\n",
    "    data = get_tweets(str(handle))\n",
    "    data.to_pickle('../data/1-' + str(filename) + '_tweets.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of tuples containing filename for pickle and twitter handle\n",
    "all_spcas = [('sfspca', 'sfspca'), ('pspca', 'PSPCA'), ('houston', 'HoustonSPCA'), ('texas', 'spcaoftexas'),\n",
    "            ('tulsa', 'Tulsa_SPCA'), ('richmond', 'RichmondSPCA'), ('ontario', 'OntarioSPCA'), \n",
    "            ('alberta', 'FMSPCA'), ('bc', 'BC_SPCA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for filename, handle in all_spcas:\n",
    "    count += 1\n",
    "    print('Pulling {} of {}: {}'.format(count, len(all_spcas), handle))\n",
    "    get_and_export(filename, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
