{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7 - Fit a Blender Model for Final Prediction\n",
    "The purpose of this notebook is to train a regression model on the predictions created from the models in Layer 1 of the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Layer 1 Models and Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the data to be used for the blender\n",
    "df_blender_train = joblib.load('../data/df_blender_train.pkl')\n",
    "df_blender_test = joblib.load('../data/df_blender_test.pkl')\n",
    "y_blender_train = joblib.load('../data/y_blender_train.pkl')\n",
    "y_blender_test = joblib.load('../data/y_blender_test.pkl')\n",
    "\n",
    "# import the layer 1 processors\n",
    "text_tfidf = joblib.load('../data/4-text_tfidf.pkl')\n",
    "text_svd = joblib.load('../data/4-text_svd.pkl')\n",
    "tags_cv = joblib.load('../data/6-tags_cv.pkl')\n",
    "tags_svd = joblib.load('../data/6-tags_svd.pkl')\n",
    "\n",
    "# import the layer 1 models for the text\n",
    "text_rfr = joblib.load('../data/4-text_rfr.pkl')\n",
    "text_knr = joblib.load('../data/4-text_knr.pkl')\n",
    "text_bayes = joblib.load('../data/4-text_bayes.pkl')\n",
    "text_gbr = joblib.load('../data/4-text_gbr.pkl')\n",
    "\n",
    "# import the layer 1 models for the meta data\n",
    "meta_rfr = joblib.load('../data/5-meta_rfr.pkl')\n",
    "meta_knr = joblib.load('../data/5-meta_knr.pkl')\n",
    "meta_bayes = joblib.load('../data/5-meta_bayes.pkl')\n",
    "meta_gbr = joblib.load('../data/5-meta_gbr.pkl')\n",
    "\n",
    "# import the layer 1 models for the hashtags and mentions\n",
    "tags_rfr = joblib.load('../data/6-tags_rfr.pkl')\n",
    "tags_knr = joblib.load('../data/6-tags_knr.pkl')\n",
    "tags_bayes = joblib.load('../data/6-tags_bayes.pkl')\n",
    "tags_gbr = joblib.load('../data/6-tags_gbr.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_cv = joblib.load('../data/6-tags_cv.pkl')\n",
    "tags_svd = joblib.load('../data/6-tags_svd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Training and Test Data into Three Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the text data\n",
    "X_text_train = df_blender_train.text\n",
    "X_text_test = df_blender_test.text\n",
    "\n",
    "# get the meta data\n",
    "cols = ['year', 'month', 'hour', 'weekday', 'has_hashtag', 'has_mention', 'has_url']\n",
    "X_meta_train = df_blender_train[cols]\n",
    "X_meta_test = df_blender_test[cols]\n",
    "\n",
    "# get the hashtags and mentions data\n",
    "X_tags_train = df_blender_train.hashtags_and_mentions\n",
    "X_tags_test = df_blender_test.hashtags_and_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Blender\n",
    "Here are the steps to train the blender:\n",
    "1. Run the data through layer 1 to get predictions\n",
    "1. Train a model with the predictions as the input\n",
    "1. Score the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Layer 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get predictions from layer 1\n",
    "def get_layer1_preds(data, regr, dataset=None):\n",
    "    '''\n",
    "    Runs the data through the layer 1 models to get predictions\n",
    "    \n",
    "    Parameters:\n",
    "        data - feature data to be used in prediction\n",
    "        regr - fitted regressor\n",
    "        dataset - string that specifies which kind of layer1 data to process \n",
    "                  (text, meta, or tags)\n",
    "    \n",
    "    Returns: array with shape = [num_samples] containing predictions \n",
    "    '''\n",
    "    \n",
    "    if dataset not in ['text', 'meta', 'tags']:\n",
    "        print(\"Must specify 'text', 'meta', or 'tags'.\")\n",
    "        return\n",
    "    \n",
    "    # transform the text if predicting on text or hashtags and mentions \n",
    "    if dataset == 'text':\n",
    "        sparse = text_tfidf.transform(data)\n",
    "        data = text_svd.transform(sparse)\n",
    "    elif dataset == 'tags':\n",
    "        sparse = tags_cv.transform(data)\n",
    "        data = tags_svd.transform(sparse)\n",
    "        \n",
    "    return regr.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through all the Layer 1 models and build predictions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text predictions complete.\n",
      "\n",
      "All meta predictions complete.\n",
      "\n",
      "All tags predictions complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_preds_dict = {}\n",
    "test_preds_dict = {}\n",
    "\n",
    "# loop through the text models\n",
    "text_models = [('text_rfr_preds', text_rfr), ('text_knr_preds', text_knr), \n",
    "               ('text_bayes_preds', text_bayes), ('text_gbr_preds', text_gbr)]\n",
    "for model in text_models:\n",
    "    train_preds = get_layer1_preds(X_text_train, model[1], dataset='text')\n",
    "    test_preds = get_layer1_preds(X_text_test, model[1], dataset='text')\n",
    "    title = model[0]\n",
    "    train_preds_dict[title] = train_preds\n",
    "    test_preds_dict[title] = test_preds\n",
    "print('All text predictions complete.', end='\\n\\n')\n",
    "\n",
    "# loop through the meta models\n",
    "meta_models = [('meta_rfr_preds', meta_rfr), ('meta_knr_preds', meta_knr), \n",
    "               ('meta_bayes_preds', meta_bayes), ('meta_gbr_preds', meta_gbr)]\n",
    "for model in meta_models:\n",
    "    train_preds = get_layer1_preds(X_meta_train, model[1], dataset='meta')\n",
    "    test_preds = get_layer1_preds(X_meta_test, model[1], dataset='meta')\n",
    "    title = model[0]\n",
    "    train_preds_dict[title] = train_preds\n",
    "    test_preds_dict[title] = test_preds\n",
    "print('All meta predictions complete.', end='\\n\\n')\n",
    "    \n",
    "# loop through the hashtags and mentions models\n",
    "tags_models = [('tags_rfr_preds', tags_rfr), ('tags_knr_preds', tags_knr), \n",
    "               ('tags_bayes_preds', tags_bayes), ('tags_gbr_preds', tags_gbr)]\n",
    "for model in tags_models:\n",
    "    train_preds = get_layer1_preds(X_tags_train, model[1], dataset='tags')\n",
    "    test_preds = get_layer1_preds(X_tags_test, model[1], dataset='tags')\n",
    "    title = model[0]\n",
    "    train_preds_dict[title] = train_preds\n",
    "    test_preds_dict[title] = test_preds\n",
    "print('All tags predictions complete.', end='\\n\\n')\n",
    "    \n",
    "# write the predictions to a dataframe\n",
    "X_train_preds = pd.DataFrame(train_preds_dict)\n",
    "X_test_preds = pd.DataFrame(test_preds_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to fit and score a regressor\n",
    "def fit_and_score(data, regr, return_regr=False):\n",
    "    '''\n",
    "    Fits the regressor to the training data and then prints train and test scores.\n",
    "    \n",
    "    Parameters:\n",
    "        data - iterable containing X_train, X_test, y_train, y_test\n",
    "        regr - instantiated regressor\n",
    "        return_regr - boolean, option to return the fit regressor (default: False)\n",
    "    \n",
    "    Returns: optional, regressor fit to the training data\n",
    "    '''\n",
    "    \n",
    "    print('Regressor: {}'.format(regr))\n",
    "    \n",
    "    regr.fit(data[0], data[2])\n",
    "    print('Train score: {}'.format(regr.score(data[0], data[2])))\n",
    "    \n",
    "    print('Test score: {}'.format(regr.score(data[1], data[3])))\n",
    "    \n",
    "    if return_regr:\n",
    "        return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (X_train_preds, X_test_preds, y_blender_train, y_blender_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "Train score: 0.4922951265792904\n",
      "Test score: 0.5071965117148725\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "fit_and_score(data, linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/7-blender_linreg.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linreg, '../data/7-blender_linreg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the predicted number of tweets\n",
    "final_predictions = linreg.predict(X_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_scaled</th>\n",
       "      <th>predicted_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87376</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.325723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87766</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.733436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57239</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.722085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34117</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65838</th>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.651178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_scaled  predicted_scaled\n",
       "87376       1.098612          1.325723\n",
       "87766       1.098612          1.733436\n",
       "57239       2.639057          1.722085\n",
       "34117       0.000000          0.864286\n",
       "65838       2.772589          2.651178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of predicted and actual - remember these are log-transformed values\n",
    "results_dict = {'predicted_scaled': final_predictions, 'actual_scaled': y_blender_test}\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscale the Retweets\n",
    "Since the number of retweets were scaled using log(x + 1), they need to be inverted using exp(x) - 1. Then they should be rounded to the nearest integer since there cannot be fractions of a retweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df['Actual'] = np.expm1(results_df.actual_scaled).apply(lambda x: int(round(x,0)))\n",
    "results_df['Predicted'] = np.expm1(results_df.predicted_scaled).apply(lambda x: int(round(x,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_scaled</th>\n",
       "      <th>predicted_scaled</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87376</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.325723</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87766</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.733436</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57239</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.722085</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34117</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65838</th>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.651178</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_scaled  predicted_scaled  Actual  Predicted\n",
       "87376       1.098612          1.325723       2          3\n",
       "87766       1.098612          1.733436       2          5\n",
       "57239       2.639057          1.722085      13          5\n",
       "34117       0.000000          0.864286       0          1\n",
       "65838       2.772589          2.651178      15         13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg, '../data/7-predictions.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
